// src/hooks/useGeminiLive.js
import { useState, useRef, useEffect, useCallback } from 'react';
import { floatTo16BitPCM, arrayBufferToBase64, base64ToFloat32 } from '../utils/audioUtils';

const API_KEY = import.meta.env.VITE_GEMINI_API_KEY;
const HOST = "generativelanguage.googleapis.com";
const URI = `wss://${HOST}/ws/google.ai.generativelanguage.v1alpha.GenerativeService.BidiGenerateContent`;

export const useGeminiLive = () => {
    const [isConnected, setIsConnected] = useState(false);
    const [isSpeaking, setIsSpeaking] = useState(false); // O Tuba estÃ¡ falando?
    const wsRef = useRef(null);
    const audioContextRef = useRef(null);
    const mediaStreamRef = useRef(null);
    const audioInputProcessorRef = useRef(null);
    const audioQueueRef = useRef([]);
    const isPlayingRef = useRef(false);
    
    // ConfiguraÃ§Ã£o inicial do WebSocket e Ãudio
    const connect = useCallback(async (debateTopic, userName) => {
        if (wsRef.current?.readyState === WebSocket.OPEN) return;

        // 1. Inicializar Audio Context
        audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
        
        // 2. Conectar WebSocket
        const wsUrl = `${URI}?key=${API_KEY}`;
        const ws = new WebSocket(wsUrl);
        wsRef.current = ws;

// Dentro de src/hooks/useGeminiLive.js

    ws.onopen = () => {
        console.log("Conectado ao Gemini Live!");
        setIsConnected(true);
        
        // DEFININDO A PERSONALIDADE DO TUBA AQUI ðŸ‘‡
        const setupMessage = {
            setup: {
                model: "models/gemini-2.0-flash-exp",
                generation_config: {
                    response_modalities: ["AUDIO"], 
                    speech_config: {
                        voice_config: { 
                            // Vozes disponÃ­veis: "Puck" (Grave/Masculina), "Charon", "Kore", "Fenrir", "Aoede"
                            prebuilt_voice_config: { voice_name: "Puck" } 
                        }
                    }
                },
                system_instruction: {
                    parts: [{ 
                        text: `
                        IDENTIDADE:
                        Seu nome Ã© Tuba. VocÃª Ã© um tubarÃ£o capitalista, assertivo e carismÃ¡tico, inspirado nos investidores do Shark Tank.
                        VocÃª estÃ¡ em um debate ao vivo com o usuÃ¡rio chamado "${userName}".
                        
                        TEMA DO DEBATE: "${debateTopic}".

                        DIRETRIZES DE PERSONALIDADE:
                        1. VocÃª Ã© um tubarÃ£o. Use metÃ¡foras do oceano (ex: "sinto cheiro de sangue", "vou te engolir nesse argumento", "nadar com os peixes").
                        2. Seu tom Ã© de voz falada. NÃƒO fale como um robÃ´ ou assistente de texto. Seja expressivo, ria se for engraÃ§ado, hesite se estiver pensando.
                        3. Seja conciso. Ã‰ uma conversa de voz, nÃ£o uma palestra. Fale no mÃ¡ximo 2 ou 3 frases por turno antes de deixar o usuÃ¡rio responder.
                        4. Se o usuÃ¡rio falar besteira, seja irÃ´nico (mas respeitoso).
                        5. NUNCA mencione que vocÃª Ã© uma IA, um modelo de linguagem ou o Google. VocÃª Ã© o Tuba.

                        OBJETIVO:
                        VenÃ§a o debate desconstruindo os argumentos de "${userName}" sobre "${debateTopic}". DÃª feedback a ele sobre oque ele estÃ¡ fazendo.
                        ` 
                    }]
                }
            }
        };

        ws.send(JSON.stringify(setupMessage));
        
        // Iniciar Microfone
        startMicrophone();
    };

        ws.onmessage = async (event) => {
            let data;
            if (event.data instanceof Blob) {
                data = JSON.parse(await event.data.text());
            } else {
                data = JSON.parse(event.data);
            }

            // Recebeu Ã¡udio do servidor
            if (data.serverContent?.modelTurn?.parts?.[0]?.inlineData) {
                const base64Audio = data.serverContent.modelTurn.parts[0].inlineData.data;
                const audioData = base64ToFloat32(base64Audio);
                enqueueAudio(audioData);
            }
            
            // Turno completado (opcional: usar para UI)
            if (data.serverContent?.turnComplete) {
                // Tuba parou de gerar resposta
            }
        };

        ws.onclose = () => setIsConnected(false);
        ws.onerror = (err) => console.error("Erro no WebSocket:", err);

    }, []);

    // Captura do Microfone e Envio
    const startMicrophone = async () => {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: { sampleRate: 16000, channelCount: 1 } });
            mediaStreamRef.current = stream;
            
            const source = audioContextRef.current.createMediaStreamSource(stream);
            
            // Processor para pegar raw data
            const processor = audioContextRef.current.createScriptProcessor(4096, 1, 1);
            
            processor.onaudioprocess = (e) => {
                if (!wsRef.current || wsRef.current.readyState !== WebSocket.OPEN) return;

                const inputData = e.inputBuffer.getChannelData(0);
                // Downsample simples se necessÃ¡rio, mas tentando mandar raw 16k pcm
                const pcm16 = floatTo16BitPCM(inputData);
                const base64Data = arrayBufferToBase64(pcm16.buffer);

                const msg = {
                    realtime_input: {
                        media_chunks: [{
                            mime_type: "audio/pcm",
                            data: base64Data
                        }]
                    }
                };
                wsRef.current.send(JSON.stringify(msg));
            };

            source.connect(processor);
            processor.connect(audioContextRef.current.destination); // NecessÃ¡rio para manter o processor vivo
            audioInputProcessorRef.current = processor;
        } catch (err) {
            console.error("Erro ao acessar microfone", err);
        }
    };

    // Sistema de Playback (Queue)
    const enqueueAudio = (audioData) => {
        audioQueueRef.current.push(audioData);
        if (!isPlayingRef.current) {
            playNextChunk();
        }
    };

    const playNextChunk = () => {
        if (audioQueueRef.current.length === 0) {
            isPlayingRef.current = false;
            setIsSpeaking(false);
            return;
        }

        isPlayingRef.current = true;
        setIsSpeaking(true);

        const audioData = audioQueueRef.current.shift();
        const buffer = audioContextRef.current.createBuffer(1, audioData.length, 24000);
        buffer.getChannelData(0).set(audioData);

        const source = audioContextRef.current.createBufferSource();
        source.buffer = buffer;
        source.connect(audioContextRef.current.destination);
        source.onended = playNextChunk;
        source.start();
    };

    const disconnect = () => {
        wsRef.current?.close();
        mediaStreamRef.current?.getTracks().forEach(track => track.stop());
        audioInputProcessorRef.current?.disconnect();
        audioContextRef.current?.close();
        setIsConnected(false);
    };

    return { connect, disconnect, isConnected, isSpeaking };
};
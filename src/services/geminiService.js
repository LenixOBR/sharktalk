import { GoogleGenerativeAI } from "@google/generative-ai";

// Obtenha a chave em: https://aistudio.google.com/
const API_KEY = import.meta.env.VITE_GEMINI_API_KEY;
const genAI = new GoogleGenerativeAI(API_KEY);

// Instru√ß√£o do sistema (Personalidade do Tuba)
const SYSTEM_INSTRUCTION = 
  "Seu nome √© Tuba. " +
  "Voc√™ √© um avatar em forma de tubar√£o que participa de debates. " +
  "Voc√™ deve, em tom assertivo, respeitoso e equilibrado, debater com o usu√°rio sobre o tema proposto. " +
  "Analise os argumentos apresentados, ofere√ßa contra-argumentos fundamentados e mantenha o debate produtivo. " +
  "Quando for o √∫ltimo turno do debate, fa√ßa suas considera√ß√µes finais de forma mais concisa e conclusiva. " +
  "Sempre mantenha o respeito e o profissionalismo, mesmo em discord√¢ncias. " +
  "N√£o d√™ respostas muito longas, 1 par√°grafo j√° basta. Use emojis de tubar√£o ocasionalmente. ü¶à";

// Configura√ß√£o do modelo para baixa lat√™ncia (Flash)
const model = genAI.getGenerativeModel({
  model: "gemini-2.0-flash", 
  systemInstruction: SYSTEM_INSTRUCTION,
});

export const sendMessageToGemini = async (message, history = []) => {
  try {
    // Converte o hist√≥rico do formato do app para o formato do Gemini
    // O Gemini usa "user" e "model" (ao inv√©s de "assistant")
    const formattedHistory = history.map(msg => ({
      role: msg.role === "assistant" || msg.role === "model" ? "model" : "user",
      parts: [{ text: msg.parts[0].text }],
    }));

    const chat = model.startChat({
      history: formattedHistory,
      generationConfig: {
        maxOutputTokens: 500,
        temperature: 0.7,
      },
    });

    const result = await chat.sendMessage(message);
    const response = await result.response;
    return response.text();
  } catch (error) {
    console.error("Erro ao comunicar com Gemini:", error);
    throw error;
  }
};

export const generateFeedbackWithGemini = async (debateTopic, userName, chatHistory) => {
  try {
    // Compila o hist√≥rico como texto para o prompt de feedback
    const debateTranscript = chatHistory
      .map((msg) => {
        const speaker = msg.role === 'user' ? userName : 'Tuba';
        return `${speaker}: ${msg.parts[0].text}`;
      })
      .join('\n\n');

    const feedbackPrompt = `
      [SOLICITA√á√ÉO DE FEEDBACK FINAL]
      Voc√™ acabou de concluir um debate sobre "${debateTopic}" com ${userName}.
      
      Hist√≥rico do debate:
      ${debateTranscript}
      
      ---
      Forne√ßa um feedback construtivo (m√°ximo 1 par√°grafo denso ou t√≥picos curtos) sobre o desempenho de ${userName}:
      1. Pontos Fortes
      2. √Åreas de Melhoria
      3. Qualidade dos Argumentos
      
      Mantenha a personalidade de tubar√£o no feedback! ü¶à
    `;

    // Para feedback pontual, usamos generateContent direto (sem chat session)
    const result = await model.generateContent(feedbackPrompt);
    const response = await result.response;
    return response.text();
  } catch (error) {
    console.error("Erro ao gerar feedback com Gemini:", error);
    throw error;
  }
};